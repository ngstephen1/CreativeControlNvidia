# ğŸ¬ Autonomous Studio Director  
### _AI Storyboarding â€¢ Cinematic Shot Generation â€¢ Music Video Rendering_

<p align="center">
  <img src="https://img.shields.io/badge/Streamlit-UI-ff4b4b?logo=streamlit&logoColor=white">
  <img src="https://img.shields.io/badge/FIBO-Structured%20Images-f39c12">
  <img src="https://img.shields.io/badge/LongCat-Video%20Gen-4a90e2">
  <img src="https://img.shields.io/badge/NVIDIA-Optimized-76b900?logo=nvidia&logoColor=white">
  <img src="https://img.shields.io/badge/Python-3.10+-blue">
</p>

---

## ğŸš€ Overview  
**Autonomous Studio Director** converts plain text scripts into cinematic storyboards and fully rendered music videos.  
Powered by **multi-agent reasoning**, **FIBO JSON controllability**, and **parallel video rendering**, it offers an endâ€‘toâ€‘end creative pipeline:

- Scene + shot breakdown using intelligent agents  
- FIBOâ€‘structured JSON for professionalâ€‘grade controllability  
- Briaâ€‘powered keyframe generation  
- LongCat (fal.ai) async video rendering  
- Interactive Streamlit editor for creative iteration  

This project targets film makers, creators, and AIâ€‘powered production workflows.

---

## âœ¨ Core Features  
- ğŸ­ **Multiâ€‘Agent Script â†’ Storyboard**  
- ğŸ–¼ï¸ **Highâ€‘control Image Generation** (camera, lighting, composition, palette, HDR)  
- ğŸ¬ **Music Video Renderer** with automatic shot stitching  
- ğŸ§ª **Shot Asset Lab** (RMBG, enhancements, background swaps)  
- ğŸš€ **Async Parallel Rendering** for speed + cost control  
- ğŸ“¦ **Oneâ€‘click Asset Export**  

---

## ğŸ§° Tech Stack  
- **UI:** Streamlit  
- **Backend:** FastAPI  
- **AI Models:** BRIA FIBO, ControlNetâ€‘ready architecture  
- **Video:** LongCat (fal.ai)  
- **Storage:** `/generated` asset directory  

---

## ğŸ”§ Quick Setup  

Create a `.env` file:

```
BRIA_API_TOKEN=your_bria_key  
FAL_KEY=your_fal_api_key  
RENDER_BACKEND_BASE=http://localhost:8000
```

Run the backend:

```
uvicorn app.api:app --reload
```

Run the UI:

```
streamlit run ui/storyboard_app.py
```

---

## ğŸ† Hackathon Focus  
Designed for the **FIBO Ã— NVIDIA Ã— Fal.ai Hackathon**, showcasing:  
- High controllability (camera, lighting, pose, palettes, HDR modes)  
- Multiâ€‘agent creative direction  
- Real cinematic production workflow simulation  

---

## â¤ï¸ Credits  
Built with the support of **Bria AI**, **NVIDIA**, **Fal.ai**, and the openâ€‘source community.

---

## ğŸ“¸ Demo Preview  
Hereâ€™s a quick look at what the Autonomous Studio Director produces:

- **Storyboard images** generated with professional camera + lighting control  
- **FIBO JSON blocks** showing structured cinematic intent  
- **Stitched musicâ€‘video clips** rendered through async LongCat pipelines  

*(Add your example images or GIFs to this section when available.)*

---

## ğŸ§± System Architecture (Highâ€‘Level)

```
User Script â†’ Multiâ€‘Agent Parser â†’ FIBO JSON Builder  
        â†’ Image Generator (BRIA) â†’ Keyframes  
        â†’ Parallel Video Engine (LongCat) â†’ Final MV
```

- **Agents**: handle scene splitting, camera intention, environment mapping  
- **FIBO Builder**: produces HDRâ€‘ready, controllable JSON  
- **Backend API**: orchestrates job dispatch + asset tracking  
- **Streamlit UI**: allows perâ€‘shot refinement and interactive editing  

---

## ğŸ› Advanced Controls Supported  

### Camera  
- Angle, lens, depth of field  
- Motion intent (dolly, pan, pushâ€‘in)  

### Lighting  
- Threeâ€‘point lighting  
- Noir hardâ€‘shadows  
- Sunset/warm keylight  
- Neon reflections  

### Film Stocks  
- Kodak 5219  
- Fuji Eterna  
- Custom LUT presets  

### Composition  
- Golden ratio  
- Centerâ€‘weighted portrait  
- Wide establishing frames  

---

## ğŸ—ºï¸ Feature Roadmap  

### Phase 1 â€” Completed  
- Storyboard generator  
- HDR + Controllability layers  
- Parallel video stitching  
- Continuity inspector  

### Phase 2 â€” In Progress  
- BRIA ControlNet (pose, depth, canny, colorgrid)  
- Inpainting workflow  
- Editable masks per shot  

### Phase 3 â€” Planned  
- Audioâ€‘synchronized shot timing  
- Beat detection â†’ automatic pacing  
- Direct export to Premiere Pro / Resolve  
- Multiâ€‘character continuity tracking  

---

## ğŸ“‚ Project Structure Overview  

```
CreativeControlNvidia/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api.py               # FastAPI backend
â”‚   â”œâ”€â”€ schemas.py           # Request/response models
â”‚   â””â”€â”€ utils/               # Helpers
â”‚
â”œâ”€â”€ fibo/
â”‚   â”œâ”€â”€ image_generator_bria.py
â”‚   â”œâ”€â”€ fibo_builder.py
â”‚   â””â”€â”€ presets/             # Camera/lighting/palette presets
â”‚
â”œâ”€â”€ video/
â”‚   â””â”€â”€ video_backend.py     # Async LongCat rendering
â”‚
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ storyboard_app.py    # Streamlit frontâ€‘end
â”‚
â”œâ”€â”€ generated/               # Output images + videos
â””â”€â”€ README.md
```

---

## ğŸ¤ Contributing  

Pull requests are welcome!  
If youâ€™d like to help build more cinematic controls (lens metadata, shot composition AI, or BRIA ControlNet integrations), feel free to open an issue.

---

## ğŸŒŸ If You Like This Project  
Please â­ the repo â€” it helps support ongoing development!